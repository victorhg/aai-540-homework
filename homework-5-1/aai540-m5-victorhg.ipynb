{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e8bcb0d",
   "metadata": {},
   "source": [
    "# AAI540 - Module 5 Assignment\n",
    "\n",
    "Victor Hugo Germano\n",
    "\n",
    "## ML System Observability "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ff499a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta, timezone\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import sagemaker\n",
    "import boto3\n",
    "from time import sleep\n",
    "from threading import Thread\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sagemaker import get_execution_role,  Session, image_uris\n",
    "from sagemaker.s3 import S3Downloader, S3Uploader\n",
    "from sagemaker.processing import ProcessingJob\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.model_monitor import DataCaptureConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee23e75",
   "metadata": {},
   "source": [
    "# Defining model and quality monitoring\n",
    "\n",
    "From m5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d44cc02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket: sagemaker-us-east-1-440542329720\n",
      "Role: arn:aws:iam::440542329720:role/LabRole\n",
      "Region: us-east-1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "session = sagemaker.Session()\n",
    "region = session.boto_region_name\n",
    "\n",
    "bucket = session.default_bucket()\n",
    "prefix = \"model-bias-monitoring\"\n",
    "\n",
    "print(f\"Bucket: {bucket}\")\n",
    "print(f\"Role: {role}\")\n",
    "print(f\"Region: {region}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ae89f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demo Bucket: sagemaker-us-east-1-440542329720\n",
      "Image URI: 156813124566.dkr.ecr.us-east-1.amazonaws.com/sagemaker-model-monitor-analyzer\n",
      "Capture path: s3://sagemaker-us-east-1-440542329720/sagemaker/Churn-ModelQualityMonitor-20201201/datacapture\n",
      "Ground truth path: s3://sagemaker-us-east-1-440542329720/sagemaker/Churn-ModelQualityMonitor-20201201/ground_truth_data/2026-02-09-18-48-45\n",
      "Report path: s3://sagemaker-us-east-1-440542329720/sagemaker/Churn-ModelQualityMonitor-20201201/reports\n"
     ]
    }
   ],
   "source": [
    "# Setup S3 bucket\n",
    "# You can use a different bucket, but make sure the role you chose for this notebook\n",
    "# has the s3:PutObject permissions. This is the bucket into which the data is captured\n",
    "bucket = session.default_bucket()\n",
    "print(\"Demo Bucket:\", bucket)\n",
    "prefix = \"sagemaker/Churn-ModelQualityMonitor-20201201\"\n",
    "\n",
    "##S3 prefixes\n",
    "data_capture_prefix = f\"{prefix}/datacapture\"\n",
    "s3_capture_upload_path = f\"s3://{bucket}/{data_capture_prefix}\"\n",
    "\n",
    "ground_truth_upload_path = (\n",
    "    f\"s3://{bucket}/{prefix}/ground_truth_data/{datetime.now():%Y-%m-%d-%H-%M-%S}\"\n",
    ")\n",
    "\n",
    "reports_prefix = f\"{prefix}/reports\"\n",
    "s3_report_path = f\"s3://{bucket}/{reports_prefix}\"\n",
    "\n",
    "##Get the model monitor image\n",
    "monitor_image_uri = image_uris.retrieve(framework=\"model-monitor\", region=region)\n",
    "\n",
    "print(\"Image URI:\", monitor_image_uri)\n",
    "print(f\"Capture path: {s3_capture_upload_path}\")\n",
    "print(f\"Ground truth path: {ground_truth_upload_path}\")\n",
    "print(f\"Report path: {s3_report_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e16a028a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! You are all set to proceed.\n"
     ]
    }
   ],
   "source": [
    "# Upload some test files\n",
    "S3Uploader.upload(\"test_data/upload-test-file.txt\", f\"s3://{bucket}/test_upload\")\n",
    "print(\"Success! You are all set to proceed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b837bd66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-440542329720/sagemaker/Churn-ModelQualityMonitor-20201201/xgb-churn-prediction-model.tar.gz'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Upload the pretrained model to S3\n",
    "s3_key = f\"s3://{bucket}/{prefix}\"\n",
    "model_url = S3Uploader.upload(\"model/xgb-churn-prediction-model.tar.gz\", s3_key)\n",
    "model_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef23d7c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_242/953180226.py:1: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  model_name = f\"DEMO-xgb-churn-pred-model-monitor-{datetime.utcnow():%Y-%m-%d-%H%M}\"\n"
     ]
    }
   ],
   "source": [
    "model_name = f\"DEMO-xgb-churn-pred-model-monitor-{datetime.utcnow():%Y-%m-%d-%H%M}\"\n",
    "\n",
    "image_uri = image_uris.retrieve(framework=\"xgboost\", version=\"0.90-1\", region=region)\n",
    "\n",
    "model = Model(image_uri=image_uri, model_data=model_url, role=role, sagemaker_session=session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8387176",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_242/1517134418.py:1: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  endpoint_name = f\"DEMO-xgb-churn-model-quality-monitor-{datetime.utcnow():%Y-%m-%d-%H%M}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EndpointName = DEMO-xgb-churn-model-quality-monitor-2026-02-09-1848\n",
      "-----!"
     ]
    }
   ],
   "source": [
    "endpoint_name = f\"DEMO-xgb-churn-model-quality-monitor-{datetime.utcnow():%Y-%m-%d-%H%M}\"\n",
    "print(\"EndpointName =\", endpoint_name)\n",
    "\n",
    "data_capture_config = DataCaptureConfig(\n",
    "    enable_capture=True, sampling_percentage=100, destination_s3_uri=s3_capture_upload_path\n",
    ")\n",
    "\n",
    "model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    endpoint_name=endpoint_name,\n",
    "    data_capture_config=data_capture_config,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c6a84f1-da24-4960-b3e0-ebf1374bbeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import Predictor\n",
    "\n",
    "predictor = Predictor(\n",
    "    endpoint_name=endpoint_name, sagemaker_session=session, serializer=CSVSerializer()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa508fb1",
   "metadata": {},
   "source": [
    "model monitor data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3583b118",
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_cutoff = 0.8\n",
    "validate_dataset = \"validation_with_predictions.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f04aed50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........................................................................................................................................................................................................\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "limit = 200  # Need at least 200 samples to compute standard deviations\n",
    "i = 0\n",
    "with open(f\"test_data/{validate_dataset}\", \"w\") as baseline_file:\n",
    "    baseline_file.write(\"probability,prediction,label\\n\")  # our header\n",
    "    with open(\"test_data/validation.csv\", \"r\") as f:\n",
    "        for row in f:\n",
    "            (label, input_cols) = row.split(\",\", 1)\n",
    "            probability = float(predictor.predict(input_cols))\n",
    "            prediction = \"1\" if probability > churn_cutoff else \"0\"\n",
    "            baseline_file.write(f\"{probability},{prediction},{label}\\n\")\n",
    "            i += 1\n",
    "            if i > limit:\n",
    "                break\n",
    "            print(\".\", end=\"\", flush=True)\n",
    "            sleep(0.5)\n",
    "print()\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc866906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probability,prediction,label\n",
      "0.01516005303710699,0,0\n",
      "0.1684480607509613,0,0\n",
      "0.21427156031131744,0,0\n",
      "0.06330718100070953,0,0\n",
      "0.02791607193648815,0,0\n",
      "0.014169521629810333,0,0\n",
      "0.00571369007229805,0,0\n",
      "0.10534518957138062,0,0\n",
      "0.025899196043610573,0,0\n"
     ]
    }
   ],
   "source": [
    "!head test_data/validation_with_predictions.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bba651bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline data uri: s3://sagemaker-us-east-1-440542329720/sagemaker/Churn-ModelQualityMonitor-20201201/baselining/data\n",
      "Baseline results uri: s3://sagemaker-us-east-1-440542329720/sagemaker/Churn-ModelQualityMonitor-20201201/baselining/results\n"
     ]
    }
   ],
   "source": [
    "baseline_prefix = prefix + \"/baselining\"\n",
    "baseline_data_prefix = baseline_prefix + \"/data\"\n",
    "baseline_results_prefix = baseline_prefix + \"/results\"\n",
    "\n",
    "baseline_data_uri = f\"s3://{bucket}/{baseline_data_prefix}\"\n",
    "baseline_results_uri = f\"s3://{bucket}/{baseline_results_prefix}\"\n",
    "print(f\"Baseline data uri: {baseline_data_uri}\")\n",
    "print(f\"Baseline results uri: {baseline_results_uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "39c4bc61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-440542329720/sagemaker/Churn-ModelQualityMonitor-20201201/baselining/data/validation_with_predictions.csv'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_dataset_uri = S3Uploader.upload(f\"test_data/{validate_dataset}\", baseline_data_uri)\n",
    "baseline_dataset_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79762ee",
   "metadata": {},
   "source": [
    "quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c1f5550e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model_monitor import ModelQualityMonitor\n",
    "from sagemaker.model_monitor import EndpointInput\n",
    "from sagemaker.model_monitor.dataset_format import DatasetFormat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ea37a427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model quality monitoring object\n",
    "churn_model_quality_monitor = ModelQualityMonitor(\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    volume_size_in_gb=20,\n",
    "    max_runtime_in_seconds=1800,\n",
    "    sagemaker_session=session,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "263b1bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_242/478642366.py:2: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  baseline_job_name = f\"DEMO-xgb-churn-model-baseline-job-{datetime.utcnow():%Y-%m-%d-%H%M}\"\n"
     ]
    }
   ],
   "source": [
    "# Name of the model quality baseline job\n",
    "baseline_job_name = f\"DEMO-xgb-churn-model-baseline-job-{datetime.utcnow():%Y-%m-%d-%H%M}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f3b28905",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating processing-job with name DEMO-xgb-churn-model-baseline-job-2026-02-09-1854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".........................................................................................!"
     ]
    }
   ],
   "source": [
    "# Execute the baseline suggestion job.\n",
    "# You will specify problem type, in this case Binary Classification, and provide other required attributes.\n",
    "job = churn_model_quality_monitor.suggest_baseline(\n",
    "    job_name=baseline_job_name,\n",
    "    baseline_dataset=baseline_dataset_uri,\n",
    "    dataset_format=DatasetFormat.csv(header=True),\n",
    "    output_s3_uri=baseline_results_uri,\n",
    "    problem_type=\"BinaryClassification\",\n",
    "    inference_attribute=\"prediction\",\n",
    "    probability_attribute=\"probability\",\n",
    "    ground_truth_attribute=\"label\",\n",
    ")\n",
    "job.wait(logs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0343e2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_job = churn_model_quality_monitor.latest_baselining_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1d699cb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>confusion_matrix.0.0</th>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>confusion_matrix.0.1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>confusion_matrix.1.0</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>confusion_matrix.1.1</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall.value</th>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall.standard_deviation</th>\n",
       "      <td>0.043912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision.value</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision.standard_deviation</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy.value</th>\n",
       "      <td>0.940299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy.standard_deviation</th>\n",
       "      <td>0.004897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_best_constant_classifier.value</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_best_constant_classifier.standard_deviation</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_best_constant_classifier.value</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_best_constant_classifier.standard_deviation</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy_best_constant_classifier.value</th>\n",
       "      <td>0.860697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy_best_constant_classifier.standard_deviation</th>\n",
       "      <td>0.014745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_positive_rate.value</th>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_positive_rate.standard_deviation</th>\n",
       "      <td>0.043912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_negative_rate.value</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_negative_rate.standard_deviation</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>false_positive_rate.value</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>false_positive_rate.standard_deviation</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>false_negative_rate.value</th>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>false_negative_rate.standard_deviation</th>\n",
       "      <td>0.043912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>receiver_operating_characteristic_curve.false_positive_rates</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>receiver_operating_characteristic_curve.true_positive_rates</th>\n",
       "      <td>[0.0, 0.03571428571428571, 0.07142857142857142...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_recall_curve.precisions</th>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_recall_curve.recalls</th>\n",
       "      <td>[0.0, 0.03571428571428571, 0.07142857142857142...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auc.value</th>\n",
       "      <td>0.939513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auc.standard_deviation</th>\n",
       "      <td>0.009248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>au_prc.value</th>\n",
       "      <td>0.863272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>au_prc.standard_deviation</th>\n",
       "      <td>0.012313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f0_5.value</th>\n",
       "      <td>0.869565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f0_5.standard_deviation</th>\n",
       "      <td>0.021096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1.value</th>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1.standard_deviation</th>\n",
       "      <td>0.036202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f2.value</th>\n",
       "      <td>0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f2.standard_deviation</th>\n",
       "      <td>0.042268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f0_5_best_constant_classifier.value</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f0_5_best_constant_classifier.standard_deviation</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_best_constant_classifier.value</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_best_constant_classifier.standard_deviation</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f2_best_constant_classifier.value</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f2_best_constant_classifier.standard_deviation</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                    0\n",
       "confusion_matrix.0.0                                                                              173\n",
       "confusion_matrix.0.1                                                                                0\n",
       "confusion_matrix.1.0                                                                               12\n",
       "confusion_matrix.1.1                                                                               16\n",
       "recall.value                                                                                 0.571429\n",
       "recall.standard_deviation                                                                    0.043912\n",
       "precision.value                                                                                   1.0\n",
       "precision.standard_deviation                                                                      0.0\n",
       "accuracy.value                                                                               0.940299\n",
       "accuracy.standard_deviation                                                                  0.004897\n",
       "recall_best_constant_classifier.value                                                             0.0\n",
       "recall_best_constant_classifier.standard_deviation                                                0.0\n",
       "precision_best_constant_classifier.value                                                          0.0\n",
       "precision_best_constant_classifier.standard_dev...                                                0.0\n",
       "accuracy_best_constant_classifier.value                                                      0.860697\n",
       "accuracy_best_constant_classifier.standard_devi...                                           0.014745\n",
       "true_positive_rate.value                                                                     0.571429\n",
       "true_positive_rate.standard_deviation                                                        0.043912\n",
       "true_negative_rate.value                                                                          1.0\n",
       "true_negative_rate.standard_deviation                                                             0.0\n",
       "false_positive_rate.value                                                                         0.0\n",
       "false_positive_rate.standard_deviation                                                            0.0\n",
       "false_negative_rate.value                                                                    0.428571\n",
       "false_negative_rate.standard_deviation                                                       0.043912\n",
       "receiver_operating_characteristic_curve.false_p...  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "receiver_operating_characteristic_curve.true_po...  [0.0, 0.03571428571428571, 0.07142857142857142...\n",
       "precision_recall_curve.precisions                   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...\n",
       "precision_recall_curve.recalls                      [0.0, 0.03571428571428571, 0.07142857142857142...\n",
       "auc.value                                                                                    0.939513\n",
       "auc.standard_deviation                                                                       0.009248\n",
       "au_prc.value                                                                                 0.863272\n",
       "au_prc.standard_deviation                                                                    0.012313\n",
       "f0_5.value                                                                                   0.869565\n",
       "f0_5.standard_deviation                                                                      0.021096\n",
       "f1.value                                                                                     0.727273\n",
       "f1.standard_deviation                                                                        0.036202\n",
       "f2.value                                                                                        0.625\n",
       "f2.standard_deviation                                                                        0.042268\n",
       "f0_5_best_constant_classifier.value                                                               0.0\n",
       "f0_5_best_constant_classifier.standard_deviation                                                  0.0\n",
       "f1_best_constant_classifier.value                                                                 0.0\n",
       "f1_best_constant_classifier.standard_deviation                                                    0.0\n",
       "f2_best_constant_classifier.value                                                                 0.0\n",
       "f2_best_constant_classifier.standard_deviation                                                    0.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_metrics = baseline_job.baseline_statistics().body_dict[\"binary_classification_metrics\"]\n",
    "pd.json_normalize(binary_metrics).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0db60ff9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>comparison_operator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.571429</td>\n",
       "      <td>LessThanThreshold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>1.0</td>\n",
       "      <td>LessThanThreshold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.940299</td>\n",
       "      <td>LessThanThreshold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_positive_rate</th>\n",
       "      <td>0.571429</td>\n",
       "      <td>LessThanThreshold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_negative_rate</th>\n",
       "      <td>1.0</td>\n",
       "      <td>LessThanThreshold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>false_positive_rate</th>\n",
       "      <td>0.0</td>\n",
       "      <td>GreaterThanThreshold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>false_negative_rate</th>\n",
       "      <td>0.428571</td>\n",
       "      <td>GreaterThanThreshold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auc</th>\n",
       "      <td>0.939513</td>\n",
       "      <td>LessThanThreshold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f0_5</th>\n",
       "      <td>0.869565</td>\n",
       "      <td>LessThanThreshold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.727273</td>\n",
       "      <td>LessThanThreshold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f2</th>\n",
       "      <td>0.625</td>\n",
       "      <td>LessThanThreshold</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    threshold   comparison_operator\n",
       "recall               0.571429     LessThanThreshold\n",
       "precision                 1.0     LessThanThreshold\n",
       "accuracy             0.940299     LessThanThreshold\n",
       "true_positive_rate   0.571429     LessThanThreshold\n",
       "true_negative_rate        1.0     LessThanThreshold\n",
       "false_positive_rate       0.0  GreaterThanThreshold\n",
       "false_negative_rate  0.428571  GreaterThanThreshold\n",
       "auc                  0.939513     LessThanThreshold\n",
       "f0_5                 0.869565     LessThanThreshold\n",
       "f1                   0.727273     LessThanThreshold\n",
       "f2                      0.625     LessThanThreshold"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(baseline_job.suggested_constraints().body_dict[\"binary_classification_constraints\"]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f7b1e9",
   "metadata": {},
   "source": [
    "## Model Bias Monitor\n",
    "In this section, we will set up a Model Bias Monitor to check for bias in our model's predictions. We need to prepare a dataset that includes both the model predictions and the features (converted to a format with headers) so that the monitor can identify the sensitive attributes (facets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "234534a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created clean dataset shape: (666, 70) (Should be 70 cols: 1 label + 69 features)\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.model_monitor import ModelBiasMonitor, BiasAnalysisConfig\n",
    "from sagemaker.clarify import BiasConfig\n",
    "\n",
    "# Initialize the Model Bias Monitor\n",
    "churn_model_bias_monitor = ModelBiasMonitor(\n",
    "    role=role,\n",
    "    sagemaker_session=session,\n",
    "    max_runtime_in_seconds=1800,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    base_job_name=\"churn-bias-monitor\"\n",
    ")\n",
    "\n",
    "facet_name = \"Feature_1\"\n",
    "\n",
    "bias_config_object = BiasConfig(\n",
    "    label_values_or_threshold=[1], \n",
    "    facet_name=facet_name,\n",
    "    facet_values_or_threshold=[1], \n",
    "    group_name=None\n",
    ")\n",
    "\n",
    "# 1. Prepare a CLEAN dataset (Label + Features ONLY)\n",
    "# We exclude 'probability' and 'prediction' so they aren't sent to the model\n",
    "val_df = pd.read_csv(\"test_data/validation.csv\", header=None)\n",
    "feature_names = [f\"Feature_{i}\" for i in range(1, val_df.shape[1])]\n",
    "val_df.columns = [\"label\"] + feature_names\n",
    "\n",
    "# Save this clean version to CSV\n",
    "bias_dataset_file = \"test_data/validation_bias_clean.csv\"\n",
    "val_df.to_csv(bias_dataset_file, index=False)\n",
    "\n",
    "print(f\"Created clean dataset shape: {val_df.shape} (Should be 70 cols: 1 label + 69 features)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "70413dd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded to: s3://sagemaker-us-east-1-440542329720/sagemaker/Churn-ModelQualityMonitor-20201201/bias-baselining/data-clean/validation_bias_clean.csv\n"
     ]
    }
   ],
   "source": [
    "# 2. Upload the clean dataset\n",
    "bias_data_prefix = prefix + \"/bias-baselining/data-clean\"\n",
    "bias_data_uri = f\"s3://{bucket}/{bias_data_prefix}\"\n",
    "\n",
    "bias_dataset_s3_uri = S3Uploader.upload(bias_dataset_file, bias_data_uri)\n",
    "print(f\"Uploaded to: {bias_dataset_s3_uri}\")\n",
    "\n",
    "bias_results_prefix = prefix + \"/bias-baselining/results\"\n",
    "bias_results_uri = f\"s3://{bucket}/{bias_results_prefix}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fc9ac409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model from endpoint: sagemaker-xgboost-2026-02-09-18-48-52-925\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.clarify import DataConfig, ModelConfig, ModelPredictedLabelConfig\n",
    "\n",
    "\n",
    "data_config = DataConfig(\n",
    "    s3_data_input_path=bias_dataset_s3_uri,\n",
    "    s3_output_path=bias_results_uri,\n",
    "    label='label',\n",
    "    headers=list(val_df.columns),\n",
    "    dataset_type='text/csv'\n",
    ")\n",
    "\n",
    "# multiple runs generated errors \n",
    "# to find thed appropriate endpoint name \n",
    "# using the datatime object\n",
    "endpoint_desc = session.sagemaker_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "endpoint_config_name = endpoint_desc['EndpointConfigName']\n",
    "endpoint_config_desc = session.sagemaker_client.describe_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name\n",
    ")\n",
    "actual_model_name = endpoint_config_desc['ProductionVariants'][0]['ModelName']\n",
    "\n",
    "print(f\"Using model from endpoint: {actual_model_name}\")\n",
    "\n",
    "\n",
    "model_config = ModelConfig(\n",
    "    model_name=actual_model_name,  \n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.large',\n",
    "    accept_type='text/csv',\n",
    "    content_type='text/csv'\n",
    ")\n",
    "\n",
    "model_predicted_label_config = ModelPredictedLabelConfig(\n",
    "    probability=0,\n",
    "    probability_threshold=0.8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a74812fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_242/268441169.py:2: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  job_name_bias = f\"bias-baseline-{datetime.utcnow():%Y-%m-%d-%H%M}\"\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker.clarify:Analysis Config: {'dataset_type': 'text/csv', 'headers': ['label', 'Feature_1', 'Feature_2', 'Feature_3', 'Feature_4', 'Feature_5', 'Feature_6', 'Feature_7', 'Feature_8', 'Feature_9', 'Feature_10', 'Feature_11', 'Feature_12', 'Feature_13', 'Feature_14', 'Feature_15', 'Feature_16', 'Feature_17', 'Feature_18', 'Feature_19', 'Feature_20', 'Feature_21', 'Feature_22', 'Feature_23', 'Feature_24', 'Feature_25', 'Feature_26', 'Feature_27', 'Feature_28', 'Feature_29', 'Feature_30', 'Feature_31', 'Feature_32', 'Feature_33', 'Feature_34', 'Feature_35', 'Feature_36', 'Feature_37', 'Feature_38', 'Feature_39', 'Feature_40', 'Feature_41', 'Feature_42', 'Feature_43', 'Feature_44', 'Feature_45', 'Feature_46', 'Feature_47', 'Feature_48', 'Feature_49', 'Feature_50', 'Feature_51', 'Feature_52', 'Feature_53', 'Feature_54', 'Feature_55', 'Feature_56', 'Feature_57', 'Feature_58', 'Feature_59', 'Feature_60', 'Feature_61', 'Feature_62', 'Feature_63', 'Feature_64', 'Feature_65', 'Feature_66', 'Feature_67', 'Feature_68', 'Feature_69'], 'label': 'label', 'label_values_or_threshold': [1], 'facet': [{'name_or_index': 'Feature_1', 'value_or_threshold': [1]}], 'methods': {'report': {'name': 'report', 'title': 'Analysis Report'}, 'pre_training_bias': {'methods': 'all'}, 'post_training_bias': {'methods': 'all'}}, 'predictor': {'model_name': 'sagemaker-xgboost-2026-02-09-18-48-52-925', 'instance_type': 'ml.m5.large', 'initial_instance_count': 1, 'accept_type': 'text/csv', 'content_type': 'text/csv', 'probability': 0}, 'probability_threshold': 0.8}\n",
      "INFO:sagemaker:Creating processing-job with name bias-baseline-2026-02-09-1904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bias-baseline-2026-02-09-1904\n",
      "Started Clarify Bias Baseline Job.\n",
      ".......................................................................................................................!"
     ]
    }
   ],
   "source": [
    "# 5. Run the Job\n",
    "job_name_bias = f\"bias-baseline-{datetime.utcnow():%Y-%m-%d-%H%M}\"\n",
    "print(job_name_bias)\n",
    "\n",
    "bias_job = churn_model_bias_monitor.suggest_baseline(\n",
    "    data_config=data_config,\n",
    "    bias_config=bias_config_object, \n",
    "    model_config=model_config,\n",
    "    model_predicted_label_config=model_predicted_label_config,\n",
    "    job_name=job_name_bias\n",
    ")\n",
    "\n",
    "print(\"Started Clarify Bias Baseline Job.\")\n",
    "bias_job.wait(logs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7abc29d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading analysis results from: s3://sagemaker-us-east-1-440542329720/sagemaker/Churn-ModelQualityMonitor-20201201/bias-baselining/results\n",
      "\n",
      "Pre-training Bias Metrics:\n",
      "   name                                        description     value  \\\n",
      "0  CDDL  Conditional Demographic Disparity in Labels (C...       NaN   \n",
      "1    CI                               Class Imbalance (CI) -0.996997   \n",
      "2   DPL  Difference in Positive Proportions in Labels (... -0.165414   \n",
      "3    JS                     Jensen-Shannon Divergence (JS)  0.003734   \n",
      "4    KL                   Kullback-Liebler Divergence (KL)  0.180819   \n",
      "5    KS                   Kolmogorov-Smirnov Distance (KS)  0.165414   \n",
      "6    LP                                      L-p Norm (LP)  0.165414   \n",
      "7   TVD                     Total Variation Distance (TVD)  0.082707   \n",
      "\n",
      "                                     error  \n",
      "0  Group variable is empty or not provided  \n",
      "1                                      NaN  \n",
      "2                                      NaN  \n",
      "3                                      NaN  \n",
      "4                                      NaN  \n",
      "5                                      NaN  \n",
      "6                                      NaN  \n",
      "7                                      NaN  \n",
      "\n",
      "Post-training Bias Metrics:\n",
      "     name                                        description     value  \\\n",
      "0      AD                           Accuracy Difference (AD)  0.078195   \n",
      "1   CDDPL  Conditional Demographic Disparity in Predicted...      None   \n",
      "2     DAR               Difference in Acceptance Rates (DAR)      -1.0   \n",
      "3     DCA         Difference in Conditional Acceptance (DCA) -1.896552   \n",
      "4     DCR          Difference in Conditional Rejection (DCR) -0.085667   \n",
      "5      DI                              Disparate Impact (DI)  Infinity   \n",
      "6    DPPL  Difference in Positive Proportions in Predicte... -0.087218   \n",
      "7     DRR                Difference in Rejection Rates (DRR) -0.085667   \n",
      "8      FT                                     Flip Test (FT)  0.087218   \n",
      "9      GE                           Generalized Entropy (GE)  0.042345   \n",
      "10     RD                             Recall Difference (RD) -0.527273   \n",
      "11     SD                        Specificity Difference (SD)       0.0   \n",
      "12     TE                            Treatment Equality (TE)  Infinity   \n",
      "\n",
      "                                      error  \n",
      "0                                       NaN  \n",
      "1   Group variable is empty or not provided  \n",
      "2                                       NaN  \n",
      "3                                       NaN  \n",
      "4                                       NaN  \n",
      "5                                       NaN  \n",
      "6                                       NaN  \n",
      "7                                       NaN  \n",
      "8                                       NaN  \n",
      "9                                       NaN  \n",
      "10                                      NaN  \n",
      "11                                      NaN  \n",
      "12                                      NaN  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sagemaker.s3 import S3Downloader\n",
    "import json\n",
    "\n",
    "# Get the latest job and its output location\n",
    "latest_bias_job = churn_model_bias_monitor.latest_baselining_job\n",
    "bias_output_uri = latest_bias_job.outputs[0].destination\n",
    "\n",
    "print(f\"Downloading analysis results from: {bias_output_uri}\")\n",
    "\n",
    "# Download analysis.json directly from S3\n",
    "analysis_json = S3Downloader.read_file(f\"{bias_output_uri}/analysis.json\")\n",
    "bias_metrics = json.loads(analysis_json)\n",
    "\n",
    "# Display Pre-training Bias Metrics\n",
    "if \"pre_training_bias_metrics\" in bias_metrics:\n",
    "    print(\"\\nPre-training Bias Metrics:\")\n",
    "    metrics_data = bias_metrics[\"pre_training_bias_metrics\"][\"facets\"][facet_name][0][\"metrics\"]\n",
    "    print(pd.json_normalize(metrics_data))\n",
    "\n",
    "# Display Post-training Bias Metrics (if available)\n",
    "if \"post_training_bias_metrics\" in bias_metrics:\n",
    "    print(\"\\nPost-training Bias Metrics:\")\n",
    "    metrics_data = bias_metrics[\"post_training_bias_metrics\"][\"facets\"][facet_name][0][\"metrics\"]\n",
    "    print(pd.json_normalize(metrics_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "22e85351-740f-4be0-ac0b-f7427f03b602",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Deleting endpoint with name: DEMO-xgb-churn-model-quality-monitor-2026-02-09-1848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting resource cleanup...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Deleting endpoint configuration with name: DEMO-xgb-churn-model-quality-monitor-2026-02-09-1848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted endpoint: DEMO-xgb-churn-model-quality-monitor-2026-02-09-1848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Deleting model with name: DEMO-xgb-churn-pred-model-monitor-2026-02-09-1848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted endpoint config: DEMO-xgb-churn-model-quality-monitor-2026-02-09-1848\n",
      "Could not delete model: An error occurred (ValidationException) when calling the DeleteModel operation: Could not find model \"DEMO-xgb-churn-pred-model-monitor-2026-02-09-1848\".\n",
      "Deleting objects with prefix: sagemaker/Churn-ModelQualityMonitor-20201201\n",
      "Deleting objects with prefix: test_upload\n",
      "S3 cleanup complete.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Cleanup Resources\n",
    "print(\"Starting resource cleanup...\")\n",
    "\n",
    "# 1. Delete Endpoint\n",
    "try:\n",
    "    session.delete_endpoint(endpoint_name)\n",
    "    print(f\"Deleted endpoint: {endpoint_name}\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not delete endpoint (it may not exist): {e}\")\n",
    "\n",
    "# 2. Delete Endpoint Configuration\n",
    "try:\n",
    "    session.delete_endpoint_config(endpoint_name)\n",
    "    print(f\"Deleted endpoint config: {endpoint_name}\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not delete endpoint config: {e}\")\n",
    "\n",
    "# 3. Delete Model\n",
    "try:\n",
    "    session.delete_model(model_name)\n",
    "    print(f\"Deleted model: {model_name}\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not delete model: {e}\")\n",
    "\n",
    "# 4. Delete S3 Objects\n",
    "try:\n",
    "    s3 = boto3.resource('s3')\n",
    "    bucket_resource = s3.Bucket(bucket)\n",
    "    \n",
    "    # Delete the main project prefix (contains model, data capture, baselines, etc.)\n",
    "    print(f\"Deleting objects with prefix: {prefix}\")\n",
    "    bucket_resource.objects.filter(Prefix=prefix).delete()\n",
    "    \n",
    "    # Delete the test upload prefix\n",
    "    print(f\"Deleting objects with prefix: test_upload\")\n",
    "    bucket_resource.objects.filter(Prefix=\"test_upload\").delete()\n",
    "    \n",
    "    print(\"S3 cleanup complete.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error cleaning up S3: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44902fdf-185e-4e19-bb5c-d232884bc987",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
