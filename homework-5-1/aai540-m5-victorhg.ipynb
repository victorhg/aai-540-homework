{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e8bcb0d",
   "metadata": {},
   "source": [
    "# AAI540 - Module 5 Assignment\n",
    "\n",
    "Victor Hugo Germano\n",
    "\n",
    "## ML System Observability "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff499a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "from sagemaker.session import Session, get_execution_role"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee23e75",
   "metadata": {},
   "source": [
    "# Defining model and quality monitoring\n",
    "\n",
    "From m5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d44cc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "sess = sagemaker.Session()\n",
    "region = sess.boto_region_name\n",
    "\n",
    "bucket = sess.default_bucket()\n",
    "prefix = \"model-bias-monitoring\"\n",
    "\n",
    "print(f\"Bucket: {bucket}\")\n",
    "print(f\"Role: {role}\")\n",
    "print(f\"Region: {region}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae89f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup S3 bucket\n",
    "# You can use a different bucket, but make sure the role you chose for this notebook\n",
    "# has the s3:PutObject permissions. This is the bucket into which the data is captured\n",
    "bucket = session.default_bucket()\n",
    "print(\"Demo Bucket:\", bucket)\n",
    "prefix = \"sagemaker/Churn-ModelQualityMonitor-20201201\"\n",
    "\n",
    "##S3 prefixes\n",
    "data_capture_prefix = f\"{prefix}/datacapture\"\n",
    "s3_capture_upload_path = f\"s3://{bucket}/{data_capture_prefix}\"\n",
    "\n",
    "ground_truth_upload_path = (\n",
    "    f\"s3://{bucket}/{prefix}/ground_truth_data/{datetime.now():%Y-%m-%d-%H-%M-%S}\"\n",
    ")\n",
    "\n",
    "reports_prefix = f\"{prefix}/reports\"\n",
    "s3_report_path = f\"s3://{bucket}/{reports_prefix}\"\n",
    "\n",
    "##Get the model monitor image\n",
    "monitor_image_uri = image_uris.retrieve(framework=\"model-monitor\", region=region)\n",
    "\n",
    "print(\"Image URI:\", monitor_image_uri)\n",
    "print(f\"Capture path: {s3_capture_upload_path}\")\n",
    "print(f\"Ground truth path: {ground_truth_upload_path}\")\n",
    "print(f\"Report path: {s3_report_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16a028a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload some test files\n",
    "S3Uploader.upload(\"test_data/upload-test-file.txt\", f\"s3://{bucket}/test_upload\")\n",
    "print(\"Success! You are all set to proceed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b837bd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Upload the pretrained model to S3\n",
    "s3_key = f\"s3://{bucket}/{prefix}\"\n",
    "model_url = S3Uploader.upload(\"model/xgb-churn-prediction-model.tar.gz\", s3_key)\n",
    "model_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef23d7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = f\"DEMO-xgb-churn-pred-model-monitor-{datetime.utcnow():%Y-%m-%d-%H%M}\"\n",
    "\n",
    "image_uri = image_uris.retrieve(framework=\"xgboost\", version=\"0.90-1\", region=region)\n",
    "\n",
    "model = Model(image_uri=image_uri, model_data=model_url, role=role, sagemaker_session=session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8387176",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = f\"DEMO-xgb-churn-model-quality-monitor-{datetime.utcnow():%Y-%m-%d-%H%M}\"\n",
    "print(\"EndpointName =\", endpoint_name)\n",
    "\n",
    "data_capture_config = DataCaptureConfig(\n",
    "    enable_capture=True, sampling_percentage=100, destination_s3_uri=s3_capture_upload_path\n",
    ")\n",
    "\n",
    "model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    endpoint_name=endpoint_name,\n",
    "    data_capture_config=data_capture_config,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa508fb1",
   "metadata": {},
   "source": [
    "model monitor data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3583b118",
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_cutoff = 0.8\n",
    "validate_dataset = \"validation_with_predictions.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04aed50",
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = 200  # Need at least 200 samples to compute standard deviations\n",
    "i = 0\n",
    "with open(f\"test_data/{validate_dataset}\", \"w\") as baseline_file:\n",
    "    baseline_file.write(\"probability,prediction,label\\n\")  # our header\n",
    "    with open(\"test_data/validation.csv\", \"r\") as f:\n",
    "        for row in f:\n",
    "            (label, input_cols) = row.split(\",\", 1)\n",
    "            probability = float(predictor.predict(input_cols))\n",
    "            prediction = \"1\" if probability > churn_cutoff else \"0\"\n",
    "            baseline_file.write(f\"{probability},{prediction},{label}\\n\")\n",
    "            i += 1\n",
    "            if i > limit:\n",
    "                break\n",
    "            print(\".\", end=\"\", flush=True)\n",
    "            sleep(0.5)\n",
    "print()\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc866906",
   "metadata": {},
   "outputs": [],
   "source": [
    "!head test_data/validation_with_predictions.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba651bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_prefix = prefix + \"/baselining\"\n",
    "baseline_data_prefix = baseline_prefix + \"/data\"\n",
    "baseline_results_prefix = baseline_prefix + \"/results\"\n",
    "\n",
    "baseline_data_uri = f\"s3://{bucket}/{baseline_data_prefix}\"\n",
    "baseline_results_uri = f\"s3://{bucket}/{baseline_results_prefix}\"\n",
    "print(f\"Baseline data uri: {baseline_data_uri}\")\n",
    "print(f\"Baseline results uri: {baseline_results_uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c4bc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_dataset_uri = S3Uploader.upload(f\"test_data/{validate_dataset}\", baseline_data_uri)\n",
    "baseline_dataset_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79762ee",
   "metadata": {},
   "source": [
    "quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f5550e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model_monitor import ModelQualityMonitor\n",
    "from sagemaker.model_monitor import EndpointInput\n",
    "from sagemaker.model_monitor.dataset_format import DatasetFormat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea37a427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model quality monitoring object\n",
    "churn_model_quality_monitor = ModelQualityMonitor(\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    volume_size_in_gb=20,\n",
    "    max_runtime_in_seconds=1800,\n",
    "    sagemaker_session=session,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263b1bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name of the model quality baseline job\n",
    "baseline_job_name = f\"DEMO-xgb-churn-model-baseline-job-{datetime.utcnow():%Y-%m-%d-%H%M}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b28905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the baseline suggestion job.\n",
    "# You will specify problem type, in this case Binary Classification, and provide other required attributes.\n",
    "job = churn_model_quality_monitor.suggest_baseline(\n",
    "    job_name=baseline_job_name,\n",
    "    baseline_dataset=baseline_dataset_uri,\n",
    "    dataset_format=DatasetFormat.csv(header=True),\n",
    "    output_s3_uri=baseline_results_uri,\n",
    "    problem_type=\"BinaryClassification\",\n",
    "    inference_attribute=\"prediction\",\n",
    "    probability_attribute=\"probability\",\n",
    "    ground_truth_attribute=\"label\",\n",
    ")\n",
    "job.wait(logs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0343e2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_job = churn_model_quality_monitor.latest_baselining_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d699cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_metrics = baseline_job.baseline_statistics().body_dict[\"binary_classification_metrics\"]\n",
    "pd.json_normalize(binary_metrics).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db60ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(baseline_job.suggested_constraints().body_dict[\"binary_classification_constraints\"]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f7b1e9",
   "metadata": {},
   "source": [
    "## Model Bias Monitor\n",
    "In this section, we will set up a Model Bias Monitor to check for bias in our model's predictions. We need to prepare a dataset that includes both the model predictions and the features (converted to a format with headers) so that the monitor can identify the sensitive attributes (facets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234534a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model_monitor import ModelBiasMonitor, BiasAnalysisConfig\n",
    "\n",
    "# Load validation data (Ground Truth + Features)\n",
    "val_df = pd.read_csv(\"test_data/validation.csv\", header=None)\n",
    "\n",
    "feature_names = [f\"Feature_{i}\" for i in range(1, val_df.shape[1])]\n",
    "val_df.columns = [\"label\"] + feature_names\n",
    "\n",
    "pred_df = pd.read_csv(\"test_data/validation_with_predictions.csv\")\n",
    "\n",
    "# Create a combined dataset\n",
    "bias_df = pd.concat([pred_df[[\"probability\", \"prediction\"]], val_df], axis=1)\n",
    "\n",
    "bias_dataset_file = \"test_data/validation_for_bias.csv\"\n",
    "bias_df.to_csv(bias_dataset_file, index=False)\n",
    "\n",
    "print(f\"Created bias dataset with shape: {bias_df.shape}\")\n",
    "print(f\"Columns: {list(bias_df.columns)[:5]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70413dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the bias dataset to S3\n",
    "bias_data_prefix = prefix + \"/bias-baselining/data\"\n",
    "bias_data_uri = f\"s3://{bucket}/{bias_data_prefix}\"\n",
    "\n",
    "bias_dataset_s3_uri = S3Uploader.upload(bias_dataset_file, bias_data_uri)\n",
    "print(f\"Uploaded bias dataset to: {bias_dataset_s3_uri}\")\n",
    "\n",
    "\n",
    "bias_results_prefix = prefix + \"/bias-baselining/results\"\n",
    "bias_results_uri = f\"s3://{bucket}/{bias_results_prefix}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9ac409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Model Bias Monitor\n",
    "churn_model_bias_monitor = ModelBiasMonitor(\n",
    "    role=role,\n",
    "    sagemaker_session=session,\n",
    "    max_runtime_in_seconds=1800,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    base_job_name=\"churn-bias-monitor\"\n",
    ")\n",
    "\n",
    "facet_name = \"Feature_1\"  # In a real scenario, you would map this to 'Age', 'Gender', or 'Area Code'\n",
    "\n",
    "bias_analysis_config = BiasAnalysisConfig(\n",
    "    bias_config={\n",
    "        \"label_values_or_threshold\": [1], \n",
    "        \"facet_name\": facet_name,\n",
    "        \"facet_values_or_threshold\": [1], \n",
    "        \"group_name\": None\n",
    "    },\n",
    "    headers=list(bias_df.columns),\n",
    "    label=\"label\",\n",
    "    probability=\"probability\",\n",
    "    probability_threshold_attribute=0.5 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74812fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the Bias Baseline Job\n",
    "bias_job = churn_model_bias_monitor.suggest_baseline(\n",
    "    bias_config=bias_analysis_config,\n",
    "    baseline_dataset=bias_dataset_s3_uri,\n",
    "    dataset_format=DatasetFormat.csv(header=True),\n",
    "    output_s3_uri=bias_results_uri,\n",
    "    job_name=f\"bias-baseline-{datetime.utcnow():%Y-%m-%d-%H%M}\"\n",
    ")\n",
    "\n",
    "print(\"Started Bias Baseline Job. Waiting for completion...\")\n",
    "bias_job.wait(logs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abc29d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the results\n",
    "latest_bias_job = churn_model_bias_monitor.latest_baselining_job\n",
    "bias_metrics = latest_bias_job.baseline_statistics().body_dict\n",
    "print(\"Bias Metrics:\")\n",
    "pd.json_normalize(bias_metrics)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
